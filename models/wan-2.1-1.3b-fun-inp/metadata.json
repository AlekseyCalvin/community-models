{
  "name" : "Wan 2.1 1.3B Fun InP",
  "version" : "wan_v2.1_1.3b",
  "modifier" : "inpainting",
  "autoencoder" : "wan_v2.1_video_vae_f16.ckpt",
  "prefix" : "",
  "default_scale" : 8,
  "hires_fix_scale" : 12,
  "file" : "wan_2.1_1.3b_fun_inp_f16.ckpt",
  "upcast_attention" : false,
  "text_encoder" : "umt5_xxl_encoder_q8p.ckpt",
  "clip_encoder" : "open_clip_xlm_roberta_large_vit_h14_f16.ckpt",
  "high_precision_autoencoder": false,
  "objective" : {
    "u" : {
      "condition_scale" : 1000
    }
  },
  "frames_per_second": 16,
  "tea_cache_coefficients": [-5.21862437e+04, 9.23041404e+03, -5.28275948e+02, 1.36987616e+01, -4.99875664e-02],
  "note": "[Wan2.1 1.3B Fun InP](https://huggingface.co/alibaba-pai/Wan2.1-Fun-1.3B-InP) is a state-of-the-art image-to-video model developed by Alibaba PAI. It can generate video clips of up to 4 seconds in length. The model is trained at multiple resolutions, supports up to 81 frames, with a recommended shift value of 5.0. Text Guidance should be somewhere between 3 to 7. Wan2.1 is trained with Flow Matching objective, Trailing samplers would give the best result.",
  "converted": {
    "wan_v2.1_video_vae_f16.ckpt": "4c518b128b3c1f2ea164aa46269d8875b4be3661d1fc0fba2709d03fa94e418b",
    "umt5_xxl_encoder_q8p.ckpt": "72ef62d22c09a3b764ac9e6fe0100f4029619fb3ff8ccec3432e509487b29831",
    "open_clip_xlm_roberta_large_vit_h14_f16.ckpt": "362c9940a36acce5a4e13b9167d5daebd005ac026443cd37b7955ac0acd72083",
    "wan_2.1_1.3b_fun_inp_f16.ckpt": "64daf7f270305e5977866fe2086fa8319b5239a36d683e15c2f2f7ecb2dabb44",
    "wan_2.1_1.3b_fun_inp_q8p.ckpt": "b6a46f4bbb4f42506062f68eaba57d5064e49ac9fe0fe48eb8411e4b6bc3c354"
  }
}
